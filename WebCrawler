/*
KOMPLEKSITETI:
Spider: 2+2+2 = O(1);
search: n+((n-1)+(n-1)+(n-1)+1+1+1+1+1+1+1+1)(logn+logn)=6nlogn+10logn+n = O(nlogn);
nextURL: 1+(n-1)+1+n+1+1=2n+3 = O(n);

*/

import java.io.BufferedWriter;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.io.PrintWriter;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Set;

public class WebCrawler{
	
  private static final int MAX = 10; //vendos numrin maksimal te faqeve te cilave do iu kontrollojme cdo link.
                                     //e heqim si parameter ose vendosim nje numer shume te madh nqs duam te vazhdojme per nje kohe te gjate
  private Set<String> visitedPages = new HashSet<String>(); //nje set ku do vendosim faqet e vizituara
  private List<String> pagesToVisit = new LinkedList<String>(); //nje liste me faqet qe na kane ngelur per te vizituar
 
  

  /**
  *Funksioni kryesor qe do thirret ne main per kerkimin e linkeve.
  *
  *@param URL - linku i fillimit
  *@param depth - thellesia e kerkimit
  *@param directory - direktoria ku do ruhet skedari me rezultatet
  *
  *@throws IOException 
  */
  
  public void search(String URL, int depth, String directory) throws IOException{
	  
      while(this.visitedPages.size() < MAX){//per sa kohe numri i faqeve qe kemi kerkuar nuk ka kaluar limitin
    	  
          String currentURL;
          SpiderLeg leg = new SpiderLeg(); //ndertojme nje crawler te ri
	  
          if(this.pagesToVisit.isEmpty()){ //nqs nga URL ku u nisem nuk kemi me faqe per te vizituar 
              currentURL = URL;
              FileWriter fw = new FileWriter(directory+".txt", true);
          	
      	    BufferedWriter bw = new BufferedWriter(fw);
      	    bw.write(URL); 
      	    bw.newLine();
      	    bw.close(); //shtojme URLne e nisjes ne skedarin me URLte e vizituara
              this.visitedPages.add(URL); //dhe ne setin me URL te vizituara
          }
	  
          else{  
              currentURL = this.nextURL(); //perndryshe vazhdojme marrim linket e rradhes nga URL ku jemi
          }
          leg.crawl(currentURL,directory); //f
          
          this.pagesToVisit.addAll(leg.getLinks()); //shtojme linket e reja qe gjetem te lista me faqet qe do kene rradhen te vizitohen
      }
      System.out.println("\n Fundi i operimit: U vizituan " + this.visitedPages.size() + " faqe");
  }


 //funksion qe merr URL e rradhes per tu vizituar 
  private String nextURL() throws IOException{
	  
      String nextURL;
      do{
          nextURL = this.pagesToVisit.remove(0);
      } 
      while(this.visitedPages.contains(nextURL));
      this.visitedPages.add(nextURL);
      
    return nextURL;
  }
}
